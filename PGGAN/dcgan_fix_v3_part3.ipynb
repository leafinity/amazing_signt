{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "from utils import ideal_crop \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm_notebook\n",
    "import pathlib\n",
    "import helper\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "# from layer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_image(image):\n",
    "    std_height, std_width = 544, 960\n",
    "    image = np.array(image).astype('float32')/255.\n",
    "    height, width = image.shape[:2]\n",
    "    if (height/std_height)<=(width/std_width):\n",
    "        r = height/std_height\n",
    "    else:\n",
    "        r = width/std_width\n",
    "    new_height, new_width = int(std_height*r), int(std_width*r)\n",
    "    h_center, w_center = height//2, width//2\n",
    "        \n",
    "    image = image[int(h_center-(new_height//2)):int(h_center-(new_height//2)+new_height), \n",
    "                  int(w_center-(new_width//2)):int(w_center-(new_width//2)+new_width)]\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1809946d112540528974e12ba8d3cf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10973), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imgs_list = glob('/home/jovyan/ta-hsi-datacenter/resize_544_9600/mountain/*.jpg')\n",
    "imgs = []\n",
    "for i in tqdm_notebook(imgs_list):\n",
    "    img = cv2.imread(i)[:,:,::-1]\n",
    "    img = crop_resize_image(img)\n",
    "    img = np.array(img, dtype=np.float16)\n",
    "    imgs.append(img)\n",
    "imgs = np.array(imgs, dtype=np.float16)\n",
    "\n",
    "imgs_arr = [imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../../ta-hsi-datacenter/output_results/model/resize_68_120/G1_68_120.json', 'r') as json_file:\n",
    "    temp = json_file.read()\n",
    "    G1 = model_from_json(temp)\n",
    "    G1.load_weights('../../ta-hsi-datacenter/output_results/weight/resize_68_120/g1.h5')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "with open('../../ta-hsi-datacenter/output_results/model/resize_68_120/D1_68_120.json', 'r') as json_file:\n",
    "    temp = json_file.read()\n",
    "    old_D1 = model_from_json(temp)\n",
    "    old_D1.load_weights('../../ta-hsi-datacenter/output_results/weight/resize_68_120/d1.h5')\n",
    "    \n",
    "    \n",
    "    \n",
    "# with open('../../ta-hsi-datacenter/output_results/model/resize_68_120/GAN1_68_120.json', 'r') as json_file:\n",
    "#     temp = json_file.read()\n",
    "#     GAN1 = model_from_json(temp)\n",
    "#     GAN1.load_weights('../../ta-hsi-datacenter/output_results/weight/resize_68_120/gan1.h5')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(res_input,conv_dim):\n",
    "    x = layers.Conv2D(conv_dim, 3, strides=1, padding='same')(res_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(conv_dim, 3, strides=1, padding='same')(x)\n",
    "    x = layers.add([x, res_input])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_g1_blocklayers(model):\n",
    "    out = model.layers[-3]\n",
    "\n",
    "    x = residual_block(out.output,128)\n",
    "    x = layers.UpSampling2D(size=(2, 2))(out.output)\n",
    "    x = layers.Conv2DTranspose(64,(3,3),strides=(1,1),padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)   \n",
    "    x = layers.Conv2DTranspose(64,(3,3),strides=(1,1),padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    result = layers.Conv2DTranspose(3,(1,1),strides=(1,1),padding='same',activation='linear')(x)\n",
    "\n",
    "    model = Model(model.input,result)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_d1_blocklayers(model):\n",
    "    \n",
    "#     discriminator_input = layers.Input(shape=(136, 240, 3))\n",
    "\n",
    "#     x = layers.Conv2D(64, 1, padding = 'same')(discriminator_input)\n",
    "#     x = layers.LeakyReLU(0.2)(x)\n",
    "#     x = layers.Conv2D(64, 3, padding = 'same')(x)\n",
    "#     x = layers.LeakyReLU(0.2)(x)\n",
    "#     x = layers.Conv2D(128, 3, padding = 'same')(x)\n",
    "#     x = layers.LeakyReLU(0.2)(x)\n",
    "#     x = layers.AveragePooling2D()(x)\n",
    "#     x = residual_block(x,128)\n",
    "    \n",
    "\n",
    "#     model = Model(temp_model.input,x)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 130560)            26242560  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 17, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 34, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 34, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 68, 120, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 68, 120, 128)      295040    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 68, 120, 3)        387       \n",
      "=================================================================\n",
      "Total params: 27,865,731\n",
      "Trainable params: 27,865,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = add_g1_blocklayers(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 130560)            26242560  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 17, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 34, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 34, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 68, 120, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 68, 120, 128)      295040    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 136, 240, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 136, 240, 64)      73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 136, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 136, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 136, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 136, 240, 3)       195       \n",
      "=================================================================\n",
      "Total params: 27,976,259\n",
      "Trainable params: 27,976,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "def build_generator(latent_dim, output_size):\n",
    "    filter_num = [256, 128, 64 , 32]\n",
    "    generator_input = keras.Input(shape=(latent_dim,))\n",
    "    \n",
    "    \n",
    "    height, width = output_size\n",
    "    \n",
    "    x = layers.Dense(filter_num[0] * int(height//4) * int(width//4))(generator_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Reshape((int(height//4), int(width//4), filter_num[0]))(x) \n",
    "    \n",
    "    #### 17*30*256\n",
    "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(filter_num[0],(3,3),strides=(1,1),padding='same')(x)  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2DTranspose(filter_num[0],(3,3),strides=(1,1),padding='same' )(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    #### 34*60*128\n",
    "           \n",
    "#     x = residual_block(x,filter_num[0])\n",
    "#     x = residual_block(x,filter_num[0])\n",
    "#     x = layers.Conv2DTranspose(filter_num[1],(5,5),strides=(2,2),padding='same')(x)\n",
    "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(filter_num[1],(3,3),strides=(1,1),padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)   \n",
    "    x = layers.Conv2DTranspose(filter_num[1],(3,3),strides=(1,1),padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x) \n",
    "\n",
    "    \n",
    "    \n",
    "#     x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "#     x = layers.Conv2DTranspose(filter_num[2],(3,3),strides=(1,1),padding='same')(x)\n",
    "#     x = layers.LeakyReLU(0.2)(x)   \n",
    "#     x = layers.Conv2DTranspose(filter_num[2],(3,3),strides=(1,1),padding='same')(x)\n",
    "#     x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2DTranspose(3,(1,1),strides=(1,1),padding='same',activation='linear')(x)\n",
    "    \n",
    "    \n",
    "    generator = keras.models.Model(generator_input,x)\n",
    "    \n",
    "    return keras.models.Model(generator_input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bc836ce93e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m136\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_generator' is not defined"
     ]
    }
   ],
   "source": [
    "G1 = build_generator(200, (544,960))\n",
    "G1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_size):\n",
    "    height, width, channels = input_size\n",
    "    filter_num = [128,256]\n",
    "    \n",
    "    discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(64, 1, padding = 'same')(discriminator_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2D(64, 3, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2D(128, 3, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.AveragePooling2D()(x)\n",
    "#     x = residual_block(x,128)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2D(filter_num[0], 3, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2D(filter_num[0], 3, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.AveragePooling2D()(x)\n",
    "    \n",
    "    #### 272*480*16\n",
    "#     x = MinibatchStatConcatLayer(averaging='all', name='Dstat')(x)\n",
    "#     x = add_minibatch_stddev_feat(x)\n",
    "    x = layers.Conv2D(filter_num[1], 3, strides = 1, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Conv2D(filter_num[1], 4, strides = 1, padding = 'same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.AveragePooling2D()(x)\n",
    "    \n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    discriminator = keras.models.Model(discriminator_input, x)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_split = [3,5,7,9,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 68, 120, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 68, 120, 128)      3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 34, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 34, 60, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 60, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 17, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 130561    \n",
      "=================================================================\n",
      "Total params: 1,773,313\n",
      "Trainable params: 1,773,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "old_D1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 136, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 136, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 136, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 136, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 136, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 136, 240, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 136, 240, 128)     0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 68, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 68, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 34, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 34, 60, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 34, 60, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 34, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 17, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 130560)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 130561    \n",
      "=================================================================\n",
      "Total params: 1,880,769\n",
      "Trainable params: 1,880,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D1 = build_discriminator((136, 240,3))\n",
    "D1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weights = [layer.get_weights() for layer in old_D1.layers[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## residual block\n",
    "# for i in range(len(temp_weights)):\n",
    "#     D1.layers[i+13].set_weights(temp_weights[i])\n",
    "    \n",
    "\n",
    "for i in range(len(temp_weights)):\n",
    "    D1.layers[i+8].set_weights(temp_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G1.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in D1.layers[13:]:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in G1.layers[-7:]:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_GAN(G, D):\n",
    "    D.trainable = False\n",
    "    gan_input = G.input\n",
    "    gan_output = D(G(gan_input))\n",
    "    gan = keras.models.Model(gan_input, gan_output)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 136, 240, 3)       27976259  \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 1880769   \n",
      "=================================================================\n",
      "Total params: 29,857,028\n",
      "Trainable params: 27,976,259\n",
      "Non-trainable params: 1,880,769\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN = build_GAN(G1, D1)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "latent_dim = 200\n",
    "height_1, width_1 = 136, 240\n",
    "height_2, width_2 = 544, 960\n",
    "\n",
    "# G1 = build_generator(latent_dim, (height_1, width_1))\n",
    "# D1 = build_discriminator((height_1, width_1, 3))\n",
    "# optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "D1.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
    "\n",
    "GAN1 = build_GAN(G1, D1)\n",
    "optimizer = keras.optimizers.Adam(lr = 0.0001, beta_1 = 0.5)\n",
    "GAN1.compile(loss = 'binary_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = G1.to_json()\n",
    "os.path\n",
    "with open(\"generator.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from keras.preprocessing import image\n",
    "# import time\n",
    "\n",
    "# start_time_all = time.time()\n",
    "\n",
    "\n",
    "# save_dir = '../../ta-hsi-datacenter/output_results/result_image'\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "\n",
    "# # Start training loop\n",
    "# start = 0\n",
    "# start_time = time.time()\n",
    "\n",
    "# low_iteration = 600\n",
    "# high_iteration = 1000\n",
    "# pre_low_step = 55300\n",
    "# pre_high_step = 5700\n",
    "# batch_size = 16\n",
    "# for step in range(iterations):\n",
    "#     for low_step in range(low_iteration):\n",
    "#         real_images = next(datagen_train_2x)[0]\n",
    "# #         stop = start+batch_size\n",
    "# #         real_images = x_train[start: stop]\n",
    "# #         batch_size = real_images.shape[0]\n",
    "#         random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "        \n",
    "        \n",
    "#         generated_images = G1.predict(random_latent_vectors)\n",
    "        \n",
    "#         labels = np.concatenate([np.zeros((batch_size, 1)),\n",
    "#                              np.ones((batch_size, 1))])\n",
    "\n",
    "#         labels_real = np.ones((batch_size, 1)) - 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "#         labels_fake = np.zeros((batch_size, 1)) + 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "\n",
    "#         d_loss_real = D1.train_on_batch(real_images, labels_real)\n",
    "#         d_loss_fake = D1.train_on_batch(generated_images, labels_fake)\n",
    "#         d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#         random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "#         misleading_targets = np.ones((batch_size, 1))\n",
    "\n",
    "#         g_loss = GAN1.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "# #         start += batch_size\n",
    "# #         if start > len(x_train) - batch_size:\n",
    "# #             start = 0\n",
    "\n",
    "#         if low_step % 100 == 0:\n",
    "#             # Save model weights\n",
    "#             GAN1.save_weights('../../ta-hsi-datacenter/output_results/weight/gan1.h5')\n",
    "#             G1.save_weights('../../ta-hsi-datacenter/output_results/weight/g1.h5')\n",
    "#             D1.save_weights('../../ta-hsi-datacenter/output_results/weight/d1.h5')\n",
    "\n",
    "#             # Print metrics\n",
    "#             print('low resolution, discriminator loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, d_loss))\n",
    "#             print('low resolution, adversarial loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, g_loss))\n",
    "#             display_grid = np.zeros((4*height_1,width_1,3))\n",
    "        \n",
    "#             for j in range(4):\n",
    "#                 display_grid[j*height_1:(j+1)*height_1,0:width_1,:] = generated_images[j]\n",
    "        \n",
    "#             img = image.array_to_img((display_grid[:,:,::-1]*127.5)+127.5, scale=False)\n",
    "#             img.save(os.path.join(save_dir, 'low_generated_' + str(step*low_iteration+low_step+pre_low_step) + '.png'))\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_split = [7,9,11,13,15]\n",
    "#D_split = [3,5,7,9,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_layers = {0:[7,15,3,14],1:[9,15,5,14],2:[11,15,7,14],3:[13,15,9,14],4:[15,15,14,14]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(imgs_arr[0][0]*255,dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0\n",
      "low resolution, discriminator loss at step 0: 18.641347885131836\n",
      "low resolution, adversarial loss at step 0: 1.3793268e-05\n",
      "--- 10.761106967926025 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 100: 38.76502227783203\n",
      "low resolution, adversarial loss at step 100: 7.9541604e-25\n",
      "--- 23.474636793136597 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 200: 34.60512161254883\n",
      "low resolution, adversarial loss at step 200: 5.2039624e-31\n",
      "--- 23.48907470703125 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 300: 35.48690414428711\n",
      "low resolution, adversarial loss at step 300: 1.2205809e-24\n",
      "--- 31.613715887069702 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 400: 33.00086975097656\n",
      "low resolution, adversarial loss at step 400: 3.2899313e-27\n",
      "--- 28.74228310585022 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 500: 41.51607894897461\n",
      "low resolution, adversarial loss at step 500: 1.5210889e-19\n",
      "--- 23.717429876327515 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 600: 35.70257568359375\n",
      "low resolution, adversarial loss at step 600: 7.0191534e-29\n",
      "--- 23.598904848098755 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 700: 38.96186828613281\n",
      "low resolution, adversarial loss at step 700: 3.8934568e-23\n",
      "--- 26.18662738800049 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 800: 38.99492645263672\n",
      "low resolution, adversarial loss at step 800: 1.077104e-21\n",
      "--- 23.2480046749115 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 900: 35.303741455078125\n",
      "low resolution, adversarial loss at step 900: 1.1879195e-22\n",
      "--- 25.262736082077026 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 1000: 32.98284912109375\n",
      "low resolution, adversarial loss at step 1000: 2.9188236e-17\n",
      "--- 23.421419382095337 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 1100: 41.305511474609375\n",
      "low resolution, adversarial loss at step 1100: 1.665111e-23\n",
      "--- 23.340702056884766 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 1200: 34.344573974609375\n",
      "low resolution, adversarial loss at step 1200: 4.0393116e-29\n",
      "--- 30.637688875198364 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 1300: 39.436065673828125\n",
      "low resolution, adversarial loss at step 1300: 7.126404e-30\n",
      "--- 23.459800004959106 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 600: 40.676551818847656\n",
      "low resolution, adversarial loss at step 600: 2.8830877e-22\n",
      "--- 20.526100635528564 seconds ---\n",
      "level_0\n",
      "low resolution, discriminator loss at step 700: 39.58850860595703\n",
      "low resolution, adversarial loss at step 700: 1.4846556e-26\n",
      "--- 23.51573157310486 seconds ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d8bddd58bf28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             labels = np.concatenate([np.zeros((batch_size, 1)),\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1165\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3217\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m-> 3219\u001b[0;31m                                  [x.numpy() for x in outputs])\n\u001b[0m\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3217\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m-> 3219\u001b[0;31m                                  [x.numpy() for x in outputs])\n\u001b[0m\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resource handles are not convertible to numpy.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpu_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m   \u001b[0;31m# __int__, __float__ and __index__ may copy the tensor to CPU and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_cpu_nograd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mCPU\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mbacked\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \"\"\"\n\u001b[0;32m--> 899\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy_nograd\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "start_time_all = time.time()\n",
    "\n",
    "\n",
    "save_dir = '../../ta-hsi-datacenter/output_results/result_image/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "start_time = time.time()\n",
    "\n",
    "low_iteration = 600\n",
    "high_iteration = 1000\n",
    "pre_low_step = 0\n",
    "pre_high_step = 0\n",
    "batch_size = 8\n",
    "\n",
    "batch_num = len(imgs_arr[0])//batch_size\n",
    "# imgs_temp = imgs[:batch_size*batch_num]\n",
    "\n",
    "\n",
    "for idx,imgs in enumerate(imgs_arr):\n",
    "    imgs_temp = imgs[:batch_size*batch_num]\n",
    "    \n",
    "    for step in range(iterations):\n",
    "        imgs_temp = shuffle(imgs_temp)\n",
    "\n",
    "    #     ## 每一次epoch 都要慢慢解鎖layer\n",
    "    #     for num_split,split_loc_arr in split_layers.items():\n",
    "    #         imgs_temp = imgs_arr[num_split][:batch_size*batch_num]\n",
    "    #         imgs_temp = shuffle(imgs_temp)\n",
    "    #         if num_split!=4:\n",
    "    #             ###############\n",
    "    #             g_split_start , g_split_end , d_split_start , d_split_end = split_loc_arr[0],split_loc_arr[1],split_loc_arr[2],split_loc_arr[3]\n",
    "    #             ## generator部分上鎖\n",
    "    #             for k in range(g_split_start,g_split_end):\n",
    "    #                 G1.layers[k].trainable=False\n",
    "    #             ## discriminator部分上鎖\n",
    "    #             for k in range(d_split_start,d_split_end):\n",
    "    #                 D1.layers[k].trainable=False\n",
    "    #             ###############    \n",
    "\n",
    "        for low_step in range(batch_num):\n",
    "            real_images = imgs_temp[low_step*batch_size:(low_step+1)*batch_size]\n",
    "            real_images = (real_images-0.5)*2\n",
    "            random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "\n",
    "            generated_images = G1.predict(random_latent_vectors)\n",
    "\n",
    "            labels = np.concatenate([np.zeros((batch_size, 1)),\n",
    "                                 np.ones((batch_size, 1))])\n",
    "\n",
    "    #         labels_real = np.ones((batch_size, 1)) - 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "    #         labels_fake = np.zeros((batch_size, 1)) + 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "\n",
    "            labels_real = 0.9*np.ones((batch_size, 1)) \n",
    "            labels_fake = np.zeros((batch_size, 1)) \n",
    "\n",
    "            d_loss_real = D1.train_on_batch(real_images, labels_real)\n",
    "            d_loss_fake = D1.train_on_batch(generated_images, labels_fake)\n",
    "            d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#             #### discriminator部分解鎖\n",
    "#             for i in range(d_split_start,d_split_end):\n",
    "#                 D1.layers[i].trainable=True\n",
    "\n",
    "            random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "            misleading_targets = np.ones((batch_size, 1))\n",
    "\n",
    "            g_loss = GAN1.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "\n",
    "\n",
    "            if low_step % 100 == 0:\n",
    "                # Save model weights\n",
    "                GAN1.save_weights('../../ta-hsi-datacenter/output_results/weight/gan1.h5')\n",
    "                G1.save_weights('../../ta-hsi-datacenter/output_results/weight/g1.h5')\n",
    "                D1.save_weights('../../ta-hsi-datacenter/output_results/weight/d1.h5')\n",
    "                \n",
    "                # Print metrics\n",
    "                print('level_{}'.format(idx))\n",
    "                print('low resolution, discriminator loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, d_loss))\n",
    "                print('low resolution, adversarial loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, g_loss))\n",
    "                display_grid = np.zeros((4*height_1,width_1,3))\n",
    "\n",
    "                for j in range(4):\n",
    "                    display_grid[j*height_1:(j+1)*height_1,0:width_1,:] = generated_images[j]\n",
    "                \n",
    "                img = image.array_to_img((display_grid[:,:,::-1]*127.5)+127.5, scale=False)\n",
    "                img.save(os.path.join(save_dir, 'level_{}_low_generated_'.format(idx) + str(step*low_iteration+low_step+pre_low_step) + '.png'))\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                start_time = time.time()\n",
    "\n",
    "    #         if num_split!=4:\n",
    "    #             ## generator部分解鎖\n",
    "    #             for k in range(g_split_start,g_split_end):\n",
    "    #                 G1.layers[k].trainable=True\n",
    "    #             ## discriminator部分解鎖\n",
    "    #             for k in range(d_split_start,d_split_end):\n",
    "    #                 D1.layers[k].trainable=True\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.get_layer(G.layers[5]._name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.layers[5]._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "gl7jcC7TdPTG",
    "outputId": "e9d7161f-1f84-44d1-dae8-5563b75d283f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
