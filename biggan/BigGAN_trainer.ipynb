{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ops import *\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from SpectralNormalizationKeras import DenseSN, ConvSN2D, ConvSN2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import conv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember to change the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/scene/lake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 1024\n",
    "img_cols = 1024\n",
    "channels = 3\n",
    "hs = img_rows//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = [os.path.join( path, each) for each in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_list):\n",
    "    data = np.zeros([len(img_list), 512, 512, 3], dtype='float32')\n",
    "    for each in img_list:\n",
    "        img = cv2.imread(each)\n",
    "        img = img.astype('float32')/127.5 - 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = load_img(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "z_dim = 128\n",
    "sn = True\n",
    "is_training = True\n",
    "c_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_shape, is_training=True):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(1, 1, z_dim))\n",
    "    \n",
    "    split_dim = 16\n",
    "    split_dim_remainder = z_dim - (split_dim * 7)\n",
    "    z_split = tf.split(inputs, num_or_size_splits=8, axis=-1)\n",
    "    #z_split = tf.split(input_shape, num_or_size_splits=[split_dim] * 7 + [split_dim_remainder], axis=-1)\n",
    "    \n",
    "    ch = 16 * 96\n",
    "    \n",
    "    x = fully_conneted(z_split[0], units=4 * 4 * ch, sn=sn, scope='generator/dense')\n",
    "    \n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, 4, 4, ch])\n",
    "    \n",
    "    x = resblock_up_condition(x, z_split[1], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='generator/resblock_up_16')\n",
    "    ch = ch // 2\n",
    "    \n",
    "    x = resblock_up_condition(x, z_split[2], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='generator/resblock_up_8_0')    \n",
    "    x = resblock_up_condition(x, z_split[3], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='generator/resblock_up_8_1')\n",
    "    ch = ch // 2\n",
    "\n",
    "    \n",
    "    x = resblock_up_condition(x, z_split[4], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='generator/resblock_up_4')\n",
    "    \n",
    "    # Non-Local Block\n",
    "    x = self_attention_2(x, channels=ch, sn=sn, scope='self_attention')\n",
    "    ch = ch // 2\n",
    "    \n",
    "    x = resblock_up_condition(x, z_split[5], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_up_2')\n",
    "    ch = ch // 2\n",
    "\n",
    "    x = resblock_up_condition(x, z_split[6], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_up_1_0')\n",
    "    x = resblock_up_condition(x, z_split[7], channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_up_1_1')\n",
    "\n",
    "    x = batch_norm(x, is_training)\n",
    "    x = relu(x)\n",
    "    x = conv(x, channels=c_dim, kernel=3, stride=1, pad=1, use_bias=False, sn=sn, scope='G_logit')\n",
    "\n",
    "    x = tanh(x)\n",
    "    \n",
    "    G = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator((1, 1, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape, is_training=True):\n",
    "\n",
    "    ch = 16\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "#     x = inputs\n",
    "\n",
    "    x = resblock_down(inputs, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_1_0')\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_1_1')\n",
    "    ch = ch * 2\n",
    "\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_2')\n",
    "\n",
    "    # Non-Local Block\n",
    "    x = self_attention_2(x, channels=ch, sn=sn, scope='self_attention')\n",
    "    ch = ch * 2\n",
    "\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_4')\n",
    "    ch = ch * 2\n",
    "\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_8_0')\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_8_1')\n",
    "    ch = ch * 2\n",
    "\n",
    "    x = resblock_down(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock_down_16')\n",
    "\n",
    "    x = resblock(x, channels=ch, use_bias=False, is_training=is_training, sn=sn, scope='resblock')\n",
    "    x = relu(x)\n",
    "\n",
    "    x = global_sum_pooling(x)\n",
    "\n",
    "    x = fully_conneted(x, units=1, sn=sn, scope='D_logit')\n",
    "\n",
    "    D = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator((512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real, fake):\n",
    "\n",
    "    alpha = tf.random.uniform(shape=[real.shape[0], 1, 1, 1], minval=0., maxval=1.)\n",
    "    interpolated = tf.Variable(real, dtype=tf.float32) + alpha * (fake - tf.Variable(real, dtype=tf.float32))\n",
    "\n",
    "    with tf.GradientTape() as tape_p:\n",
    "        tape_p.watch(interpolated)\n",
    "        logit= D(interpolated)\n",
    "    grad = tape_p.gradient(logit, interpolated)\n",
    "    grad_norm = tf.norm(tf.reshape(grad,(batch_size, grad.shape[1]*grad.shape[2]*grad.shape[3])), axis=1)  \n",
    "    \n",
    "    GP = 10.0 * tf.reduce_mean(tf.square(grad_norm - 1.))\n",
    "\n",
    "    return GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(y_true, y_pred):\n",
    "    real_loss = -tf.reduce_mean(y_true)\n",
    "    fake_loss = tf.reduce_mean(y_pred)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(y_pred):\n",
    "    return -tf.reduce_mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_d = tf.keras.optimizers.Adam(0.0002, beta_1=0.0, beta_2=0.9)\n",
    "opt_g = tf.keras.optimizers.Adam(0.00005, beta_1=0.0, beta_2=0.9)\n",
    "# opt_e = tf.train.ExponentialMovingAverage(decay=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs[0]:real image,  inputs[1]:noise\n",
    "# @tf.function\n",
    "def train_discriminator_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        real= D(inputs[0], training=True)\n",
    "        fake_img= G(inputs[1], training=False)\n",
    "        fake = D(fake_img, training=True)\n",
    "        \n",
    "#         regularization_loss = tf.math.add_n(model.losses)\n",
    "        real_loss = discriminator_loss(real, fake)\n",
    "        \n",
    "        GP = gradient_penalty(inputs[0], fake_img)\n",
    "        \n",
    "        total_loss = real_loss  + GP\n",
    "        \n",
    "    gradients = tape.gradient(total_loss, D.trainable_variables)\n",
    "    opt_d.apply_gradients(zip(gradients, D.trainable_variables))\n",
    "    \n",
    "    return total_loss, GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def train_generator_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        img = G(inputs, training=True)\n",
    "        valid = D(img, training=False)\n",
    "#         regularization_loss = tf.math.add_n(model.losses)\n",
    "        g_loss = generator_loss(valid)\n",
    "        \n",
    "    gradients = tape.gradient(g_loss, G.trainable_variables)\n",
    "    opt_g.apply_gradients(zip(gradients, G.trainable_variables))\n",
    "#     opt_e.apply(G.trainable_variables)\n",
    "    \n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    index = np.arange(real_data.shape[0])\n",
    "    ind = shuffle(index)\n",
    "    start_time = time.time()\n",
    "    for i in range(100):\n",
    "        z = tf.random.truncated_normal(shape=[batch_size, 1, 1, z_dim], dtype=tf.float32)\n",
    "        for _ in range(5):\n",
    "            D_loss, gp_loss= train_discriminator_step([real_data[ind[i*batch_size:(i+1)*batch_size]], z])\n",
    "        G_loss = train_generator_step(z)\n",
    "\n",
    "    end_time = time.time()-start_time\n",
    "    if (epoch%1) == 0:\n",
    "        print(\"the time of the %s th epoch: \"%(epoch), end_time)\n",
    "        print(\"Finished epoch:\", epoch ,'D_loss:', D_loss.numpy(), 'GP_loss:',gp_loss.numpy(), 'G_loss:', G_loss.numpy())\n",
    "                \n",
    "        z = tf.random.truncated_normal(shape=[4, 1, 1, z_dim], dtype=tf.float32)\n",
    "        gen_img = G(z)\n",
    "        total_img = np.zeros((4*512, 512, 3))\n",
    "        for i, each in enumerate(gen_img.numpy()):\n",
    "            total_img[i*512:(i+1)*512, :, :] = each*127.5+127.5 \n",
    "        \n",
    "        total_img = total_img.astype('int64')\n",
    "        \n",
    "        ## remember construct the path\n",
    "        cv2.imwrite('./biggan_result_img/epoch_%s_result.jpg'%(epoch), total_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save_model('scene_generator_128.h5')\n",
    "D.save_model('scene_discrminator_128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
