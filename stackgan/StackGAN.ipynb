{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_image(image):\n",
    "    std_height, std_width = 68, 120\n",
    "    image = np.array(image).astype('float32')/255.\n",
    "    height, width = image.shape[:2]\n",
    "    if (height/std_height)<=(width/std_width):\n",
    "        r = height/std_height\n",
    "    else:\n",
    "        r = width/std_width\n",
    "    new_height, new_width = int(std_height*r), int(std_width*r)\n",
    "    h_center, w_center = height//2, width//2\n",
    "        \n",
    "    image = image[int(h_center-(new_height//2)):int(h_center-(new_height//2)+new_height), \n",
    "                  int(w_center-(new_width//2)):int(w_center-(new_width//2)+new_width)]\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, \n",
    "                                                       samplewise_center=False, \n",
    "                                                       featurewise_std_normalization=False, \n",
    "                                                       samplewise_std_normalization=False, \n",
    "                                                       zca_whitening=False, \n",
    "                                                       zca_epsilon=1e-06, \n",
    "                                                       rotation_range=0, \n",
    "                                                       width_shift_range=0.0, \n",
    "                                                       height_shift_range=0.0, \n",
    "                                                       brightness_range=None, \n",
    "                                                       shear_range=0.0, \n",
    "                                                       zoom_range=0.0, \n",
    "                                                       channel_shift_range=0.0, \n",
    "                                                       fill_mode='nearest', \n",
    "                                                       cval=0.0,\n",
    "                                                       horizontal_flip=False, \n",
    "                                                       vertical_flip=False, \n",
    "                                                       rescale=None, \n",
    "                                                       preprocessing_function=crop_resize_image, \n",
    "                                                       data_format=None, \n",
    "                                                       validation_split=0.0, \n",
    "                                                       dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = ['lake', 'mountain', 'ocean', 'river', 'sky']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tf.kears.datagenerator from smaller, target size dicrects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = datagen.flow_from_directory(directory='/home/jovyan/ta-hsi-datacenter/resize_272_480/', classes = [classes_dict[1]], target_size=(272, 480), batch_size = 16)\n",
    "datagen_train_2x = datagen.flow_from_directory(directory='/home/jovyan/ta-hsi-datacenter/resize_544_960/', classes = [classes_dict[1]], target_size=(544, 960), batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(datagen_train)\n",
    "plt.imshow(a[0][0])\n",
    "print(a[1][0])\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(datagen_train_2x)\n",
    "plt.imshow(a[0][0])\n",
    "print(a[1][0])\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "# latent_dim = 100\n",
    "# height = 256\n",
    "# width = 480\n",
    "# channels = 3\n",
    "\n",
    "def build_generator(latent_dim, output_size):\n",
    "    filter_num = [128, 128, 256, 256]\n",
    "    generator_input = keras.Input(shape=(latent_dim,))\n",
    "# First, transform the input into a 16x16 128-channels feature map\n",
    "    height, width = output_size\n",
    "    x = layers.Dense(128 * int(height//16) * int(width//16))(generator_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Reshape((int(height//16), int(width//16), 128))(x)\n",
    "\n",
    "# Then, add a convolution layer\n",
    "    x = layers.Conv2D(128, 4, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, 4, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    for i in range(4) :\n",
    "        x = layers.Conv2DTranspose(filter_num[i], 4, strides=2, padding='same')(x)\n",
    "        x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(3, 4, activation='tanh', padding='same')(x)\n",
    "    generator = keras.models.Model(generator_input, x)\n",
    "    generator.summary()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_generator(100, (136, 240))\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(res_input):\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(res_input)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "\n",
    "    x = layers.add([x, res_input])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_up(input_size):\n",
    "    filter_num = [256, 256]\n",
    "    height, width, channels = input_size\n",
    "    up_input = layers.Input(shape = (height, width, channels))\n",
    "    \n",
    "    x = layers.Conv2D(64, 5, padding = 'same')(up_input)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, padding = 'same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = residual_block(x)\n",
    "    x = residual_block(x)\n",
    "    \n",
    "    for i in range(1):\n",
    "        x = layers.Conv2DTranspose(filter_num[i], 4, strides=2, padding='same')(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        \n",
    "    x = layers.Conv2D(3, 3, activation='tanh', padding='same')(x)\n",
    "    generator_up = keras.models.Model(up_input, x)\n",
    "    generator_up.summary()\n",
    "    \n",
    "    return generator_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator_up((272, 480, 3))\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_size):\n",
    "    height, width, channels = input_size\n",
    "    discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(32, 4, padding = 'same')(discriminator_input)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(64, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(64, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(256, 4, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "# One dropout layer - important trick!\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# Classification layer\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    discriminator = keras.models.Model(discriminator_input, x)\n",
    "    discriminator.summary()\n",
    "    return discriminator\n",
    "# To stabilize training, we use learning rate decay\n",
    "# and gradient clipping (by value) in the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = build_discriminator((544, 960, 3))\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set discriminator weights to non-trainable\n",
    "# (will only apply to the `gan` model)\n",
    "def build_GAN(G, D):\n",
    "    D.trainable = False\n",
    "    gan_input = G.input\n",
    "#     gan_input = keras.Input(shape=(latent_dim,))\n",
    "    gan_output = D(G(gan_input))\n",
    "    gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "# gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "#     gan_optimizer = keras.optimizers.Adam(lr=0.0002, beta_1 = 0.5)\n",
    "#     gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "#     gan.summary()\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = build_GAN(G, D)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "latent_dim = 200\n",
    "height_1, width_1 = 272, 480\n",
    "height_2, width_2 = 544, 960\n",
    "\n",
    "G1 = build_generator(latent_dim, (height_1, width_1))\n",
    "D1 = build_discriminator((height_1, width_1, 3))\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "D1.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
    "\n",
    "G2 = generator_up((height_1, width_1, 3))\n",
    "D2 = build_discriminator((height_2, width_2, 3))\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "D2.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
    "\n",
    "GAN2 = build_GAN(G2, D2)\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "GAN2.compile(loss = 'binary_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN1 = build_GAN(G1, D1)\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "GAN1.compile(loss = 'binary_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "G1.load_weights('./output_3/Checkpoint/g1.h5')\n",
    "\n",
    "D1.load_weights('./output_3/Checkpoint/d1.h5')\n",
    "# optimizer = keras.optimizers.Adam(lr=0.0001, beta_1 = 0.5)\n",
    "# D1.compile(loss = 'binary_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "start_time_all = time.time()\n",
    "\n",
    "\n",
    "save_dir = './output_3/gan_images/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "start_time = time.time()\n",
    "\n",
    "low_iteration = 600\n",
    "high_iteration = 1000\n",
    "pre_low_step = 55300\n",
    "pre_high_step = 5700\n",
    "batch_size = 16\n",
    "for step in range(iterations):\n",
    "    for low_step in range(low_iteration):\n",
    "        real_images = next(datagen_train)[0]\n",
    "#         stop = start+batch_size\n",
    "#         real_images = x_train[start: stop]\n",
    "#         batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "        \n",
    "        \n",
    "        generated_images = G1.predict(random_latent_vectors)\n",
    "        \n",
    "        labels = np.concatenate([np.zeros((batch_size, 1)),\n",
    "                             np.ones((batch_size, 1))])\n",
    "\n",
    "        labels_real = np.ones((batch_size, 1)) - 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "        labels_fake = np.zeros((batch_size, 1)) + 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "\n",
    "        d_loss_real = D1.train_on_batch(real_images, labels_real)\n",
    "        d_loss_fake = D1.train_on_batch(generated_images, labels_fake)\n",
    "        d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "        misleading_targets = np.ones((batch_size, 1))\n",
    "\n",
    "        g_loss = GAN1.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "#         start += batch_size\n",
    "#         if start > len(x_train) - batch_size:\n",
    "#             start = 0\n",
    "\n",
    "        if low_step % 100 == 0:\n",
    "            # Save model weights\n",
    "            GAN1.save_weights('./output_3/gan1.h5')\n",
    "            G1.save_weights('./output_3/g1.h5')\n",
    "            D1.save_weights('./output_3/d1.h5')\n",
    "\n",
    "            # Print metrics\n",
    "            print('low resolution, discriminator loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, d_loss))\n",
    "            print('low resolution, adversarial loss at step %s: %s' % (step*low_iteration+low_step+pre_low_step, g_loss))\n",
    "            display_grid = np.zeros((4*height_1,width_1,3))\n",
    "        \n",
    "            for j in range(4):\n",
    "                display_grid[j*height_1:(j+1)*height_1,0:width_1,:] = generated_images[j]\n",
    "        \n",
    "            img = image.array_to_img((display_grid[:,:,::-1]*127.5)+127.5, scale=False)\n",
    "            img.save(os.path.join(save_dir, 'low_generated_' + str(step*low_iteration+low_step+pre_low_step) + '.png'))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "    for high_step in range(high_iteration):\n",
    "        real_images = next(datagen_train_2x)[0]\n",
    "        batch_size = real_images.shape[0]\n",
    "#        real_images = x_train2x[start: stop]\n",
    "        random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "        \n",
    "        low_generated_images = G1.predict(random_latent_vectors)\n",
    "        generated_images = G2.predict(low_generated_images)\n",
    "\n",
    "        labels_real = np.ones((batch_size, 1)) - 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "        labels_fake = np.zeros((batch_size, 1)) + 0.05*np.abs(np.random.random((batch_size, 1)))\n",
    "\n",
    "        d_loss_real = D2.train_on_batch(real_images, labels_real)\n",
    "        d_loss_fake = D2.train_on_batch(generated_images, labels_fake)\n",
    "        d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "        G1_out = G1.predict(random_latent_vectors)\n",
    "        misleading_targets = np.ones((batch_size, 1))\n",
    "        \n",
    "        g_loss = GAN2.train_on_batch(G1_out, misleading_targets)\n",
    "    \n",
    "        if high_step % 100 == 0:\n",
    "            # Save model weights\n",
    "            GAN2.save_weights('./output_3/gan2.h5')\n",
    "            G2.save_weights('./output_3/g2.h5')\n",
    "            D2.save_weights('./output_3/d2.h5')\n",
    "            # Print metrics\n",
    "            print('high resolution, discriminator loss at step %s: %s' % (step*high_iteration+high_step+pre_high_step, d_loss))\n",
    "            print('high resolution, adversarial loss at step %s: %s' % (step*high_iteration+high_step+pre_high_step, g_loss))\n",
    "            display_grid = np.zeros((4*height_2,width_2,3))\n",
    "        \n",
    "            for j in range(4):\n",
    "                display_grid[j*height_2:(j+1)*height_2,0:width_2,:] = generated_images[j]\n",
    "        \n",
    "            img = image.array_to_img((display_grid[:,:,::-1]*127.5)+127.5, scale=False)\n",
    "            img.save(os.path.join(save_dir, 'high_generated_' + str(step*high_iteration+high_step+pre_high_step) + '.png'))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(display_grid[:,:,::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
